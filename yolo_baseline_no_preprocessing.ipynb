{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Pothole Detection - YOLO Baseline (No Preprocessing)\n",
    "\n",
    "Notebook ini adalah **versi baseline** untuk perbandingan dengan YOLO + Preprocessing.\n",
    "\n",
    "**Karakteristik:**\n",
    "- ‚ùå Tidak ada preprocessing (CLAHE, sharpening, bilateral filter)\n",
    "- ‚ùå Tidak ada augmentasi data\n",
    "- ‚úÖ Training langsung dengan dataset original\n",
    "- ‚úÖ Arsitektur YOLO yang sama\n",
    "- ‚úÖ Hyperparameter yang sama\n",
    "\n",
    "**Tujuan:** Mengukur dampak preprocessing terhadap performa model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python-headless matplotlib Pillow pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Dataset Configuration\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT:** Sesuaikan path berikut dengan lokasi dataset Anda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# KONFIGURASI PATH - SESUAIKAN!\n",
    "# ============================================\n",
    "\n",
    "# Path ke dataset ORIGINAL (tanpa preprocessing)\n",
    "ORIGINAL_DATASET = '/content/pothole_dataset'  # Ganti dengan path dataset Anda\n",
    "\n",
    "# Output directory untuk hasil training\n",
    "OUTPUT_DIR = '/content/yolo_baseline_output'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Original Dataset: {ORIGINAL_DATASET}\")\n",
    "print(f\"üìÅ Output Directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 3: Inspect Dataset\n",
    "\n",
    "Verifikasi struktur dan jumlah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Inspect dataset structure and count files\n",
    "    \"\"\"\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    total_images = 0\n",
    "    total_labels = 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä DATASET INSPECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for split in splits:\n",
    "        images_path = os.path.join(dataset_path, split, 'images')\n",
    "        labels_path = os.path.join(dataset_path, split, 'labels')\n",
    "        \n",
    "        if os.path.exists(images_path):\n",
    "            num_images = len(glob.glob(os.path.join(images_path, '*.*')))\n",
    "            num_labels = len(glob.glob(os.path.join(labels_path, '*.txt')))\n",
    "            \n",
    "            total_images += num_images\n",
    "            total_labels += num_labels\n",
    "            \n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  üì∑ Images: {num_images}\")\n",
    "            print(f\"  üè∑Ô∏è  Labels: {num_labels}\")\n",
    "        else:\n",
    "            print(f\"\\n{split.upper()}: ‚ùå Not found\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä TOTAL: {total_images} images, {total_labels} labels\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return total_images\n",
    "\n",
    "# Inspect dataset\n",
    "total_data = inspect_dataset(ORIGINAL_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 4: Visualize Sample Images\n",
    "\n",
    "Tampilkan beberapa sampel gambar dari dataset original (tanpa preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_with_bbox(dataset_path, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample images with bounding boxes\n",
    "    \"\"\"\n",
    "    images_path = os.path.join(dataset_path, 'train', 'images')\n",
    "    labels_path = os.path.join(dataset_path, 'train', 'labels')\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(images_path, '*.*'))[:num_samples]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, img_path in enumerate(image_files):\n",
    "        # Read image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Read corresponding label\n",
    "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(labels_path, f\"{img_name}.txt\")\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        # YOLO format: class_id x_center y_center width height (normalized)\n",
    "                        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                        \n",
    "                        # Convert to pixel coordinates\n",
    "                        x1 = int((x_center - width/2) * w)\n",
    "                        y1 = int((y_center - height/2) * h)\n",
    "                        x2 = int((x_center + width/2) * w)\n",
    "                        y2 = int((y_center + height/2) * h)\n",
    "                        \n",
    "                        # Draw rectangle\n",
    "                        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.putText(image, 'pothole', (x1, y1-10), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[idx].imshow(image)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'Sample {idx+1} (Original)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'sample_original_images.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ Sample visualization saved!\")\n",
    "\n",
    "# Visualize samples\n",
    "visualize_sample_with_bbox(ORIGINAL_DATASET, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 5: Create data.yaml for YOLO\n",
    "\n",
    "File konfigurasi untuk training YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml\n",
    "data_yaml_path = os.path.join(ORIGINAL_DATASET, 'data.yaml')\n",
    "\n",
    "data_yaml_content = f\"\"\"\n",
    "# Dataset paths\n",
    "train: {os.path.join(ORIGINAL_DATASET, 'train', 'images')}\n",
    "val: {os.path.join(ORIGINAL_DATASET, 'valid', 'images')}\n",
    "test: {os.path.join(ORIGINAL_DATASET, 'test', 'images')}\n",
    "\n",
    "# Number of classes\n",
    "nc: 1\n",
    "\n",
    "# Class names\n",
    "names: ['pothole']\n",
    "\"\"\"\n",
    "\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    f.write(data_yaml_content.strip())\n",
    "\n",
    "print(f\"‚úÖ data.yaml created at: {data_yaml_path}\")\n",
    "print(\"\\nContent:\")\n",
    "print(data_yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ TRAINING PHASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 6: Initialize YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 model\n",
    "print(\"Initializing YOLOv8 model...\")\n",
    "model = YOLO('yolov8n.pt')  # nano model for faster training\n",
    "\n",
    "print(\"‚úÖ Model initialized successfully!\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 7: Training Configuration\n",
    "\n",
    "**Hyperparameters** (sama dengan versi preprocessing untuk perbandingan yang fair):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4  # Sesuaikan dengan kapasitas GPU/RAM Anda\n",
    "IMG_SIZE = 640\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 8: Train Model\n",
    "\n",
    "‚ö†Ô∏è **CATATAN:** Training akan memakan waktu tergantung hardware Anda.\n",
    "- GPU: ~30-60 menit\n",
    "- CPU: Beberapa jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    project='runs/detect',\n",
    "    name='pothole_yolo_baseline',\n",
    "    save=True,\n",
    "    save_period=10,  # Save checkpoint every 10 epochs\n",
    "    patience=15,  # Early stopping patience\n",
    "    verbose=True,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Results saved in: runs/detect/pothole_yolo_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä EVALUATION PHASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 9: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training results\n",
    "results_dir = 'runs/detect/pothole_yolo_baseline'\n",
    "\n",
    "# Plot training curves\n",
    "results_img = os.path.join(results_dir, 'results.png')\n",
    "if os.path.exists(results_img):\n",
    "    img = Image.open(results_img)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Training Results - Baseline (No Preprocessing)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ùå Results image not found at: {results_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 10: Load Best Model & Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "print(f\"‚úÖ Best model loaded from: {best_model_path}\")\n",
    "\n",
    "# Validate on test set\n",
    "print(\"\\nüîç Evaluating on test set...\\n\")\n",
    "metrics = best_model.val(\n",
    "    data=data_yaml_path,\n",
    "    split='test',\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TEST SET PERFORMANCE - BASELINE (NO PREPROCESSING)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 11: Visualize Predictions on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on random test images\n",
    "test_images = glob.glob(os.path.join(ORIGINAL_DATASET, 'test', 'images', '*.*'))\n",
    "sample_images = np.random.choice(test_images, size=min(6, len(test_images)), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    # Predict\n",
    "    results = best_model.predict(img_path, conf=0.25, device=DEVICE)\n",
    "    \n",
    "    # Get annotated image\n",
    "    annotated = results[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Test Image {idx+1}', fontsize=10)\n",
    "\n",
    "plt.suptitle('Predictions - Baseline Model (No Preprocessing)', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'test_predictions_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Predictions visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 12: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load confusion matrix\n",
    "conf_matrix_img = os.path.join(results_dir, 'confusion_matrix_normalized.png')\n",
    "\n",
    "if os.path.exists(conf_matrix_img):\n",
    "    img = Image.open(conf_matrix_img)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Confusion Matrix - Baseline (No Preprocessing)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ùå Confusion matrix not found at: {conf_matrix_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 13: Save Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to file\n",
    "summary_path = os.path.join(OUTPUT_DIR, 'baseline_summary.txt')\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"YOLO BASELINE RESULTS (NO PREPROCESSING)\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DATASET INFORMATION:\\n\")\n",
    "    f.write(f\"- Total Images: {total_data}\\n\")\n",
    "    f.write(f\"- Preprocessing: None\\n\")\n",
    "    f.write(f\"- Augmentation: None\\n\\n\")\n",
    "    \n",
    "    f.write(\"TRAINING CONFIGURATION:\\n\")\n",
    "    f.write(f\"- Model: YOLOv8n\\n\")\n",
    "    f.write(f\"- Epochs: {EPOCHS}\\n\")\n",
    "    f.write(f\"- Batch Size: {BATCH_SIZE}\\n\")\n",
    "    f.write(f\"- Image Size: {IMG_SIZE}\\n\")\n",
    "    f.write(f\"- Device: {DEVICE}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TEST SET PERFORMANCE:\\n\")\n",
    "    f.write(f\"- Precision: {metrics.box.mp:.4f}\\n\")\n",
    "    f.write(f\"- Recall: {metrics.box.mr:.4f}\\n\")\n",
    "    f.write(f\"- mAP@0.5: {metrics.box.map50:.4f}\\n\")\n",
    "    f.write(f\"- mAP@0.5:0.95: {metrics.box.map:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"NOTE: This is the baseline model without any preprocessing.\\n\")\n",
    "    f.write(\"Compare with preprocessing results to measure improvement.\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Summary saved to: {summary_path}\")\n",
    "\n",
    "# Display summary\n",
    "with open(summary_path, 'r') as f:\n",
    "    print(\"\\n\" + f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Step 14: Inference Demo on New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo inference on new image\n",
    "# Upload gambar baru atau gunakan dari test set\n",
    "\n",
    "# Example: pilih 1 gambar dari test set\n",
    "demo_image = test_images[0]\n",
    "\n",
    "print(f\"Testing on: {os.path.basename(demo_image)}\")\n",
    "\n",
    "# Run prediction\n",
    "results = best_model.predict(\n",
    "    source=demo_image,\n",
    "    conf=0.25,\n",
    "    device=DEVICE,\n",
    "    save=True,\n",
    "    project=OUTPUT_DIR,\n",
    "    name='inference_demo'\n",
    ")\n",
    "\n",
    "# Display result\n",
    "annotated = results[0].plot()\n",
    "annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(annotated)\n",
    "plt.axis('off')\n",
    "plt.title('Inference Demo - Baseline Model', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'inference_demo_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print detections\n",
    "print(\"\\nDetections:\")\n",
    "for box in results[0].boxes:\n",
    "    conf = box.conf.item()\n",
    "    cls = int(box.cls.item())\n",
    "    print(f\"  - Class: {best_model.names[cls]}, Confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä COMPARISON TEMPLATE\n",
    "\n",
    "Gunakan cell berikut untuk membandingkan dengan model preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 15: Performance Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template untuk perbandingan\n",
    "# Setelah training kedua model selesai, isi nilai-nilai berikut:\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä PERFORMANCE COMPARISON: BASELINE vs PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"{'Metric':<20} {'Baseline (No Prep)':<20} {'With Preprocessing':<20} {'Improvement':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Baseline metrics (sudah ada)\n",
    "baseline_precision = metrics.box.mp\n",
    "baseline_recall = metrics.box.mr\n",
    "baseline_map50 = metrics.box.map50\n",
    "baseline_map = metrics.box.map\n",
    "\n",
    "# TODO: Isi dengan hasil dari model preprocessing\n",
    "# prep_precision = 0.XXX  # Ganti dengan nilai aktual\n",
    "# prep_recall = 0.XXX\n",
    "# prep_map50 = 0.XXX\n",
    "# prep_map = 0.XXX\n",
    "\n",
    "print(f\"{'Precision':<20} {baseline_precision:<20.4f} {'TBD':<20} {'TBD':<15}\")\n",
    "print(f\"{'Recall':<20} {baseline_recall:<20.4f} {'TBD':<20} {'TBD':<15}\")\n",
    "print(f\"{'mAP@0.5':<20} {baseline_map50:<20.4f} {'TBD':<20} {'TBD':<15}\")\n",
    "print(f\"{'mAP@0.5:0.95':<20} {baseline_map:<20.4f} {'TBD':<20} {'TBD':<15}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚ö†Ô∏è NOTE: 'TBD' akan diisi setelah training model dengan preprocessing selesai\")\n",
    "print(\"\\nüí° TIP: Copy nilai dari notebook preprocessing dan uncomment code di atas untuk perbandingan lengkap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 16: Analysis & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "üìä BASELINE MODEL ANALYSIS (NO PREPROCESSING)\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "‚úÖ STRENGTHS:\n",
    "   - Faster training time (no preprocessing overhead)\n",
    "   - Simpler pipeline (fewer moving parts)\n",
    "   - Lower computational requirements\n",
    "   - Direct learning from raw data\n",
    "\n",
    "‚ùå POTENTIAL WEAKNESSES:\n",
    "   - May struggle with:\n",
    "     * Low contrast images\n",
    "     * Images with varying lighting conditions\n",
    "     * Noisy images\n",
    "     * Blurry images\n",
    "   - Limited data diversity (no augmentation)\n",
    "   - May require more training data to generalize well\n",
    "\n",
    "üîç EXPECTED IMPROVEMENTS WITH PREPROCESSING:\n",
    "   - Better feature extraction through CLAHE\n",
    "   - Improved edge detection through sharpening\n",
    "   - Noise reduction through bilateral filtering\n",
    "   - Better generalization through augmentation\n",
    "\n",
    "üìà NEXT STEPS:\n",
    "   1. Train model WITH preprocessing\n",
    "   2. Compare metrics side-by-side\n",
    "   3. Analyze error cases\n",
    "   4. Determine if preprocessing overhead is worth the improvement\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ CHECKLIST\n",
    "\n",
    "Setelah menjalankan kedua notebook (baseline & preprocessing), pastikan:\n",
    "\n",
    "- [ ] Baseline model telah di-training\n",
    "- [ ] Preprocessing model telah di-training\n",
    "- [ ] Metrics dari kedua model telah dicatat\n",
    "- [ ] Visualisasi perbandingan telah dibuat\n",
    "- [ ] Analisis perbedaan telah dilakukan\n",
    "- [ ] Kesimpulan tentang efektivitas preprocessing telah dibuat\n",
    "\n",
    "## üìö Referensi untuk Thesis:\n",
    "\n",
    "Hasil dari notebook ini akan menjadi **baseline** untuk menunjukkan improvement yang diberikan oleh preprocessing dalam thesis Anda.\n",
    "\n",
    "Pastikan untuk:\n",
    "1. Dokumentasikan semua hyperparameters yang sama\n",
    "2. Gunakan train/val/test split yang sama\n",
    "3. Catat waktu training kedua model\n",
    "4. Bandingkan inference time\n",
    "5. Analisis kasus-kasus error\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck dengan thesis-nya! üéìüöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
